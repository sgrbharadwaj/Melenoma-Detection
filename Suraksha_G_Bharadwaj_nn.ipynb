{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHZFp1IWuQrA"
      },
      "source": [
        "# **Melanoma Detection Assignment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rpXG9-QuVVo"
      },
      "source": [
        "To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APrCmFfKHQKp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPt9lPWCuXmZ"
      },
      "source": [
        "### Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8hGo10HuK8-"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAFQHOdruPET"
      },
      "outputs": [],
      "source": [
        "from glob import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBGjHh1cuiAb"
      },
      "source": [
        "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vksXwWTaueN1"
      },
      "outputs": [],
      "source": [
        "# Since we are using the data by mounting the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1DWItF4una7"
      },
      "outputs": [],
      "source": [
        "# Defining the path for train and test images\n",
        "train_dataset = pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Melenoma/Train\")\n",
        "test_dataset = pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Melenoma/Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E03MPu4uzy_"
      },
      "outputs": [],
      "source": [
        "image_count_train = len(list(train_dataset.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(test_dataset.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKyHRFuReeiC"
      },
      "source": [
        "\n",
        "Create a Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6x0Xqmbu1x-"
      },
      "outputs": [],
      "source": [
        "#Define some parameters for the loader:\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O-q2DD1fQBe"
      },
      "source": [
        "Use 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8xDzTWEfNqz"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dataset,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset='training'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsiGvTX8kKpS"
      },
      "outputs": [],
      "source": [
        "from matplotlib import test\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dataset,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    subset='validation',\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gPkZm3VneAf"
      },
      "outputs": [],
      "source": [
        "# Listing out all the classes of skin cancer and store them in a list. \n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfy9qz9ypf5T"
      },
      "source": [
        "**Visualize the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vYOpkffpHnz"
      },
      "outputs": [],
      "source": [
        "#Visualize one instance of all the class present in the dataset.\n",
        "\n",
        "#image_dataset_from_directory() will return a tf.data.Dataset that yields batches of images from the subdirectories.\n",
        "#label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index.\n",
        "image_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dataset,batch_size=32,image_size=(180,180),\n",
        "                                                                    label_mode='categorical',seed=123)\n",
        "\n",
        "#all the classes of Skin Cancer\n",
        "class_names = image_dataset.class_names\n",
        "\n",
        "#Dictionary to store the path of image as per the class\n",
        "files_path_dict = {}\n",
        "\n",
        "for cl_name in class_names:\n",
        "    files_path_dict[cl_name] = list(map(lambda x:str(train_dataset)+'/'+cl_name+'/'+x,os.listdir(str(train_dataset)+'/'+cl_name)))\n",
        "    \n",
        "#Visualize image \n",
        "plt.figure(figsize=(15,15))\n",
        "index = 0\n",
        "for cl_name in class_names:\n",
        "    path_list = files_path_dict[cl_name][:1]\n",
        "    index += 1\n",
        "    plt.subplot(3,3,index)\n",
        "    plt.imshow(load_img(path_list[0],target_size=(180,180)))\n",
        "    plt.title(cl_name)\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpmSReeLqqFi"
      },
      "source": [
        " Visualize distribution of classes in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptqgC2d-qGEm"
      },
      "outputs": [],
      "source": [
        "def class_distribution_count(directory):\n",
        "    \n",
        "    #count number of image in each classes\n",
        "    count= []\n",
        "    for path in pathlib.Path(directory).iterdir():\n",
        "        if path.is_dir():\n",
        "            count.append(len([name for name in os.listdir(path)\n",
        "                               if os.path.isfile(os.path.join(path, name))]))\n",
        "    \n",
        "    #name of the classes\n",
        "    sub_dir = [name for name in os.listdir(directory)\n",
        "                    if os.path.isdir(os.path.join(directory, name))]\n",
        "    \n",
        "    #return dataframe with image count and class.\n",
        "    return pd.DataFrame(list(zip(sub_dir,count)),columns =['Class', 'No. of Image'])\n",
        "\n",
        "df = class_distribution_count(train_dataset)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vzwXsMuq9SF"
      },
      "outputs": [],
      "source": [
        "#Visualize the data in barplot\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x=\"No. of Image\", y=\"Class\", data=df,\n",
        "            label=\"Class\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOFGyhR4tXad"
      },
      "source": [
        "### **Creating a model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7ITuxDQyiRw"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg6Chuu0rMrb"
      },
      "outputs": [],
      "source": [
        "# #`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "# #`Dataset.prefetch()` overlaps data preprocessing and model execution while training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82sEqmHsxA_Z"
      },
      "outputs": [],
      "source": [
        "#CNN Model Architecture\n",
        "\n",
        "#Sequential allows you to create models layer-by-layer  \n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.experimental.preprocessing.Rescaling(1./255,input_shape=(img_height,img_width,3)))   #Rescaling Layer\n",
        "model.add(layers.Conv2D(16,kernel_size=(5,5),activation='relu'))\n",
        "model.add(layers.Conv2D(32,kernel_size=(5,5),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(64,kernel_size=(5,5),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(len(class_names),activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZBwSTMsyDFU"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roiqFUfCxGdg"
      },
      "outputs": [],
      "source": [
        "#Compile the Model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW9MbDgzyNgG"
      },
      "outputs": [],
      "source": [
        "# View the summary of all layers\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvZPUK6wyeLb"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97S8tNgqyW66"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "history = model.fit(train_ds,validation_data=val_ds,epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7udQg4spb_eJ"
      },
      "source": [
        "### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTZZyHiVzZ3n"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwPNXIA1ccUY"
      },
      "source": [
        "**Finding on the first base model**\n",
        "\n",
        "This model is overfitting \n",
        "\n",
        "The accuracy is just around 77-90% because there are enough features to remember the pattern.\n",
        "\n",
        "But again, it's too early to comment on the overfitting & underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1iaV0fIHGMP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X1Qehy_fS1I"
      },
      "source": [
        "### Data Augmentation layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt_9x50ScFCI"
      },
      "outputs": [],
      "source": [
        "data_augument = keras.Sequential([\n",
        "                             layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\",input_shape=(img_height,img_width,3)),\n",
        "                             layers.experimental.preprocessing.RandomRotation(0.2, fill_mode='reflect'),\n",
        "                             layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3), fill_mode='reflect')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XurCxUiDfgZ3"
      },
      "outputs": [],
      "source": [
        "#visualizing how augmentation strategy works for one instance of training image.\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(data_augument(images)[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD0fgbv5jEbD"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4BhcAgKhLwk"
      },
      "outputs": [],
      "source": [
        "# This time we are using dropout layer\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "num_classes = 9\n",
        "model = Sequential([ data_augument,\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "      \n",
        "])\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkSVkqi9kSes"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4foAYp1RkJ0i"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFHf0Q1YkYqq"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cRORhGhkXLk"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "history = model.fit(train_ds,validation_data=val_ds,epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuDZFeEmIsFo"
      },
      "source": [
        "Visualising the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhUJFBx9kxEu"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeC2VAb_SUoE"
      },
      "source": [
        "**Finding from Second Model**\n",
        "\n",
        "There is no improvement in accuracy but we can definitely see the overfitting problem has solved due to data augmentation\n",
        "\n",
        "We can concentrate on increasing the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Waj3zvTCS7tA"
      },
      "source": [
        "Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl3d3UkNIqZa"
      },
      "outputs": [],
      "source": [
        "path_list=[]\n",
        "lesion_list=[]\n",
        "for i in class_names:\n",
        "      \n",
        "    for j in train_dataset.glob(i+'/*.jpg'):\n",
        "        path_list.append(str(j))\n",
        "        lesion_list.append(i)\n",
        "df_dict_original = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(df_dict_original.items()),columns = ['Path','Label'])\n",
        "original_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8MaPH89TLQ7"
      },
      "outputs": [],
      "source": [
        "df_dict_original = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(df_dict_original.items()),columns = ['Path','Label'])\n",
        "original_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKBJWQoOTb4l"
      },
      "outputs": [],
      "source": [
        "count=[]\n",
        "for i in class_names:\n",
        "    count.append(len(list(train_dataset.glob(i+'/*.jpg'))))\n",
        "plt.figure(figsize=(25,10))\n",
        "plt.bar(class_names,count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-BiE3TKfYHX"
      },
      "source": [
        "From the above details,it is clear that :\n",
        "\n",
        "\n",
        "\n",
        "*   Seborrheic Keratosis has least number of samples\n",
        "*   Actinic Keratosis and Dermatofibroma have proportionate number of classes. Basal cell Carcinoma and Nevus have proprtionate number of classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sGaBF0pTenr"
      },
      "outputs": [],
      "source": [
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gzsmB6IgC0X"
      },
      "source": [
        "Augmentor Library layer code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQFwE6WBgKXA"
      },
      "outputs": [],
      "source": [
        "pip install Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbb2wrnmf9ZW"
      },
      "outputs": [],
      "source": [
        "import Augmentor\n",
        "\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(\"/content/gdrive/MyDrive/Colab Notebooks/Melenoma/Train\",save_format='jpg')\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGU7mJ7yg_j-"
      },
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r25gmfWEgHYo"
      },
      "outputs": [],
      "source": [
        "data_dir_train1 = pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Melenoma/Train\")\n",
        "image_count_train1 = len(list(data_dir_train1.glob('*/*.jpg')))\n",
        "print(image_count_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrlyK3RbhMbv"
      },
      "outputs": [],
      "source": [
        "for i in class_names:\n",
        "      \n",
        "    for j in data_dir_train1.glob(i+'/*.jpg'):\n",
        "        path_list.append(str(j))\n",
        "        lesion_list.append(i)\n",
        "dataframe_dict_original = dict(zip(path_list, lesion_list))\n",
        "new_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\n",
        "new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2dI8QRahWGY"
      },
      "source": [
        "Lets see the distribution of augmented data after adding new images to the original training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br5r04MdhVzc"
      },
      "outputs": [],
      "source": [
        "new_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-EPFx7YhwqG"
      },
      "source": [
        "## Model 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fngmcN5h2rQ"
      },
      "source": [
        "Train Model based on augumentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BXkR8HwhP0F"
      },
      "outputs": [],
      "source": [
        "train_dataset1=pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Melenoma/Train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTKN2Cw8nzlA"
      },
      "outputs": [],
      "source": [
        "train_dataset1 = len(list(train_dataset1.glob('*/*.jpg')))\n",
        "print(train_dataset1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zl_39HGn7Pv"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "train_dataset1=pathlib.Path(\"/content/gdrive/MyDrive/Colab Notebooks/Melenoma/Train\")\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dataset1,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"training\",\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dataset1,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"validation\",\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sovcMV5e0qgb"
      },
      "outputs": [],
      "source": [
        "#create model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "num_classes = 9\n",
        "model = Sequential([ \n",
        "                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n",
        "      \n",
        "])\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (180, 180, 32)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation = \"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBF6xpMDp7t4"
      },
      "outputs": [],
      "source": [
        "#compile code\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_rokKJWqHLi"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "history = model.fit(train_ds,validation_data=val_ds,epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlnhMOYgqTeM"
      },
      "outputs": [],
      "source": [
        "#Visualise the model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpPIdvo6Odzi"
      },
      "source": [
        "**Final analysis**\n",
        "\n",
        "\n",
        "\n",
        "*   Accuracy on training data has increased by using Augmentor library\n",
        "*  Model is still overfitting.The problem of overfitting can be solved by add more layer,neurons or adding dropout layers.\n",
        "\n",
        "The Model can be further improved by tuning the hyperparameter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTR7cPH4O3Yn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Suraksha_G_Bharadwaj_nn.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}